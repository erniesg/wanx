import asyncio
import os
import logging
import random
from datetime import datetime
from dotenv import load_dotenv
from typing import Dict, Any, List, Optional
import uuid

# Import necessary functions from other modules
from .script_parser import parse_script
from .tts import text_to_speech # Still needed for Pexels segments' audio
from .pexels_client import find_and_download_videos
from .freesound_client import find_and_download_music
from .argil_client import create_argil_video_job, render_argil_video, DEFAULT_AVATAR_ID as DEFAULT_ARGIL_AVATAR_ID, DEFAULT_VOICE_ID as DEFAULT_ARGIL_VOICE_ID
# Import S3 client functions (if needed for audio uploads, though Argil might handle TTS)
from .s3_client import get_s3_client, ensure_s3_bucket, upload_to_s3

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- Configuration ---
load_dotenv()
ARGIL_API_KEY = os.getenv("ARGIL_API_KEY")
PEXELS_API_KEY = os.getenv("PEXELS_API_KEY")
FREESOUND_API_KEY = os.getenv("FREESOUND_API_KEY")
NGROK_PUBLIC_URL = os.getenv("NGROK_PUBLIC_URL")
ELEVENLABS_VOICE_ID = "oQZyHVc6FnIvc9bYS5yl" # Default voice from tts.py for Pexels segments

# S3 Configuration (primarily if we pre-generate audio for Argil, otherwise Argil handles TTS)
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")
AWS_DEFAULT_REGION = os.getenv("AWS_DEFAULT_REGION")

# Define specific avatars for Argil segments (can be customized)
# Using Argil's default for now, can be mapped per segment if needed
ARGIL_AVATARS = {
    "default": DEFAULT_ARGIL_AVATAR_ID,
    "hook": DEFAULT_ARGIL_AVATAR_ID,
    "conclusion": DEFAULT_ARGIL_AVATAR_ID
    # Add more mappings if different avatars are desired for different segments
}
ARGIL_VOICES = {
    "default": DEFAULT_ARGIL_VOICE_ID,
    # Add more mappings if different voices are desired
}

# Pexels configuration for B-roll
NUM_PEXELS_CLIPS_PER_SEGMENT = 10 # Number of clips to download per Pexels segment
MIN_PEXELS_CLIP_DURATION = 2 # Minimum seconds to show a Pexels clip
MAX_PEXELS_CLIP_DURATION = 4 # Maximum seconds to show a Pexels clip

# Segments to be generated by Argil (e.g., where an avatar speaks)
# Other segments will use Pexels for B-roll.
ARGIL_TARGET_SEGMENTS = ["hook", "conclusion"]


async def run_argil_workflow(job_id: str, script_path: str, job_data_ref: Dict, active_jobs_ref: Dict):
    """
    Orchestrates the Argil video generation workflow.
    Handles parsing, asset generation (audio for Pexels, Argil video jobs, Pexels visuals, music).
    Relies on webhooks for Argil video completion.
    """
    logger.info(f"[{job_id}] Starting Argil workflow for script: {script_path}")

    s3_client = None
    if S3_BUCKET_NAME and AWS_DEFAULT_REGION: # Only init S3 if configured, may not be needed for Argil
        s3_client = get_s3_client()
        if s3_client:
            bucket_ok = ensure_s3_bucket(s3_client, S3_BUCKET_NAME, region=AWS_DEFAULT_REGION)
            if not bucket_ok:
                logger.warning(f"[{job_id}] Failed to ensure S3 bucket '{S3_BUCKET_NAME}'. S3 uploads might fail if needed.")
                # s3_client = None # Or decide to fail if S3 is critical
        else:
            logger.warning(f"[{job_id}] S3 client could not be initialized. S3 uploads will not be possible.")

    # --- 1. Initialization ---
    if not NGROK_PUBLIC_URL:
        logger.error(f"[{job_id}] NGROK_PUBLIC_URL environment variable not set. Argil webhook will fail.")
        webhook_url = "http://localhost/invalid-webhook-url-argil" # Placeholder
    else:
        webhook_url = f"{NGROK_PUBLIC_URL.rstrip('/')}/webhooks/argil" # Ensure this matches main.py

    # Use passed-in references for state
    job_data_ref[job_id] = {
        "workflow_type": "argil", # Distinguish from heygen workflow
        "job_id": job_id,
        "status": "processing",
        "error": None,
        "creation_time": datetime.now().isoformat(),
        "input_script_path": script_path,
        "parsed_script": None,
        "assets": {
            "music_path": None,
            "music_status": "pending",
            "segments": {}
        },
        "final_video_path_raw": None,
        "caption_file_path": None,
        "final_video_path_captioned": None
    }
    if job_id not in active_jobs_ref: active_jobs_ref[job_id] = []
    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Argil Workflow initialized.")

    # --- 2. Parse Script ---
    logger.info(f"[{job_id}] Parsing script...")
    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Parsing script...")
    parsed_script = parse_script(script_path)
    if not parsed_script:
        error_msg = "Failed to parse script."
        logger.error(f"[{job_id}] {error_msg}")
        job_data_ref[job_id]["status"] = "failed"; job_data_ref[job_id]["error"] = error_msg
        active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")
        return
    job_data_ref[job_id]["parsed_script"] = parsed_script
    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Script parsed successfully.")

    # --- 3. Prepare Segments & Initiate Asset Generation ---
    script_segments = parsed_script.get("script_segments", {})
    segment_names = [name for name in script_segments.keys() if name != "production_notes"]

    if not segment_names:
        error_msg = "No script segments found."
        logger.error(f"[{job_id}] {error_msg}")
        job_data_ref[job_id]["status"] = "failed"; job_data_ref[job_id]["error"] = error_msg
        active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")
        return

    # Ensure target segments actually exist in the script
    actual_argil_segments = [name for name in ARGIL_TARGET_SEGMENTS if name in script_segments]
    logger.info(f"[{job_id}] Segments chosen for Argil: {actual_argil_segments}")

    # Define base paths for assets
    current_dir = os.path.dirname(__file__)
    # Consistent naming with heygen_workflow for assets if possible, or use 'argil_workflow' subfolder
    assets_base = os.path.join(current_dir, "..", "assets", "argil_workflow")
    audio_output_dir = os.path.join(assets_base, "temp_audio", job_id) # For Pexels segments
    pexels_output_dir = os.path.join(assets_base, "stock_video", job_id)
    music_output_dir = os.path.join(assets_base, "music", job_id)

    os.makedirs(audio_output_dir, exist_ok=True)
    os.makedirs(pexels_output_dir, exist_ok=True)
    os.makedirs(music_output_dir, exist_ok=True)

    for segment_name in segment_names:
        segment_data = script_segments[segment_name]
        voiceover_text = segment_data.get("voiceover")
        b_roll_keywords = segment_data.get("b_roll_keywords", [])

        segment_type = "argil" if segment_name in actual_argil_segments else "pexels"
        job_data_ref[job_id]["assets"]["segments"][segment_name] = {
            "type": segment_type,
            "audio_path": None, # For Pexels segments; Argil handles its own TTS
            "audio_status": "pending",
            "visual_status": "pending", # For Argil, means job created; for Pexels, means downloaded
        }
        segment_state = job_data_ref[job_id]["assets"]["segments"][segment_name]

        if not voiceover_text and segment_type == "argil":
            logger.warning(f"[{job_id}] Argil Segment '{segment_name}' has no voiceover text. Argil job might fail or produce silent video.")
            # Allow to proceed, Argil might handle empty transcript in a specific way or fail.
        elif not voiceover_text and segment_type == "pexels":
             logger.warning(f"[{job_id}] Pexels Segment '{segment_name}' has no voiceover text. Skipping audio generation for it.")
             segment_state["audio_status"] = "skipped"


        # --- Asset Generation ---
        if segment_type == "argil":
            segment_state["visual_status"] = "processing" # Argil job creation is the first step
            avatar_id_to_use = ARGIL_AVATARS.get(segment_name, ARGIL_AVATARS["default"])
            voice_id_to_use = ARGIL_VOICES.get(segment_name, ARGIL_VOICES["default"]) # Argil voice selection
            segment_state["argil_avatar_id"] = avatar_id_to_use
            segment_state["argil_voice_id"] = voice_id_to_use

            # Argil handles its own TTS based on the transcript.
            # No separate audio generation step like ElevenLabs needed here for Argil segments.
            segment_state["audio_status"] = "n/a (Argil TTS)"

            logger.info(f"[{job_id}] Initiating Argil video job for segment: {segment_name} (Avatar: {avatar_id_to_use})")
            active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Creating Argil video job for {segment_name}...")

            argil_job_title = f"{job_id}_{segment_name}_{uuid.uuid4().hex[:8]}"
            # The callback_id for Argil webhook needs to be job_id + segment_name
            argil_callback_id = f"{job_id}__{segment_name}"

            creation_response = create_argil_video_job(
                api_key=ARGIL_API_KEY,
                video_title=argil_job_title,
                full_transcript=voiceover_text or " ", # Send space if no transcript to avoid error, Argil might handle
                avatar_id=avatar_id_to_use,
                voice_id=voice_id_to_use,
                aspect_ratio="9:16", # Or make configurable
                callback_id=argil_callback_id # Passed to Argil's 'extras' for webhook matching
            )

            if creation_response and creation_response.get("success"):
                argil_video_id = creation_response.get("video_id")
                segment_state["argil_video_id"] = argil_video_id
                logger.info(f"[{job_id}] Argil video job created for {segment_name}. Argil Video ID: {argil_video_id}. Now attempting to render.")
                active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Argil video job created for {segment_name} (ID: {argil_video_id}). Rendering...")

                # Immediately try to render the video
                render_response = render_argil_video(ARGIL_API_KEY, argil_video_id)
                if render_response and render_response.get("success"):
                    logger.info(f"[{job_id}] Argil video render request successful for {segment_name} (ID: {argil_video_id}). Waiting for webhook.")
                    # Visual status remains "processing" until webhook confirms completion or failure.
                else:
                    error_msg = f"Failed to start Argil video render for {segment_name} (ID: {argil_video_id}). Response: {render_response}"
                    logger.error(f"[{job_id}] {error_msg}")
                    segment_state["visual_status"] = "failed"
                    segment_state["error"] = error_msg
                    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")
            else:
                error_msg = f"Failed to create Argil video job for {segment_name}. Response: {creation_response}"
                logger.error(f"[{job_id}] {error_msg}")
                segment_state["visual_status"] = "failed"
                segment_state["error"] = error_msg
                active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")

        elif segment_type == "pexels":
            # --- 3a. Generate Audio (ElevenLabs) for Pexels segments ---
            if segment_state["audio_status"] != "skipped" and voiceover_text:
                logger.info(f"[{job_id}] Initiating audio generation for Pexels segment: {segment_name}")
                active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Generating audio for Pexels segment {segment_name}...")
                audio_filename = f"segment_{segment_name}.mp3"
                # audio_full_path = os.path.join(audio_output_dir, audio_filename) # tts returns full path
                try:
                    # text_to_speech function saves file and returns its path
                    generated_audio_path = text_to_speech(voiceover_text, audio_filename, voice_id=ELEVENLABS_VOICE_ID, output_dir_base=audio_output_dir)
                    if generated_audio_path and os.path.exists(generated_audio_path):
                        segment_state["audio_path"] = generated_audio_path
                        segment_state["audio_status"] = "completed"
                        logger.info(f"[{job_id}] Audio completed for Pexels segment {segment_name}: {generated_audio_path}")
                        active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Audio completed for Pexels segment {segment_name}.")
                    else:
                        raise ValueError("text_to_speech failed or returned invalid path")
                except Exception as e:
                    error_msg = f"Audio generation failed for Pexels segment {segment_name}: {e}"
                    logger.error(f"[{job_id}] {error_msg}")
                    segment_state["audio_status"] = "failed"
                    segment_state["error"] = error_msg
                    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")
            elif not voiceover_text:
                 segment_state["audio_status"] = "skipped" # Double check if already skipped

            # --- 3b. Initiate Pexels Visuals ---
            if not b_roll_keywords:
                logger.warning(f"[{job_id}] Pexels Segment '{segment_name}' has no keywords. Skipping visuals.")
                segment_state["visual_status"] = "skipped"
            else:
                query = " ".join(b_roll_keywords)
                segment_state["pexels_query"] = query
                logger.info(f"[{job_id}] Initiating Pexels search for segment: {segment_name} (Query: {query}, Count: {NUM_PEXELS_CLIPS_PER_SEGMENT})")
                active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Finding Pexels videos for {segment_name}...")
                try:
                    downloaded_paths = find_and_download_videos(
                        api_key=PEXELS_API_KEY,
                        query=query,
                        count=NUM_PEXELS_CLIPS_PER_SEGMENT,
                        output_dir=pexels_output_dir, # Pass full output dir per job
                        orientation="portrait"
                    )
                    if downloaded_paths:
                        segment_state["pexels_video_paths"] = downloaded_paths
                        # Add random durations for each clip for the editor later
                        segment_state["pexels_clips_durations"] = [
                            random.uniform(MIN_PEXELS_CLIP_DURATION, MAX_PEXELS_CLIP_DURATION)
                            for _ in downloaded_paths
                        ]
                        segment_state["visual_status"] = "completed"
                        logger.info(f"[{job_id}] {len(downloaded_paths)} Pexels videos downloaded for {segment_name}.")
                        active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Pexels videos downloaded for {segment_name}.")
                    else:
                         raise ValueError(f"find_and_download_videos returned no paths for query: {query}")
                except Exception as e:
                    error_msg = f"Pexels video download failed for {segment_name}: {e}"
                    logger.error(f"[{job_id}] {error_msg}")
                    segment_state["visual_status"] = "failed"
                    segment_state["error"] = error_msg
                    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")

    # --- 4. Initiate Music Download ---
    music_query = parsed_script.get("production_notes", {}).get("music_vibe")
    if music_query:
        logger.info(f"[{job_id}] Initiating music search (Query: {music_query})")
        active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Searching for background music...")
        music_filename = f"background_music_{job_id}.mp3" # Ensure unique filename
        # Construct the full output path before calling
        music_full_path = os.path.join(music_output_dir, music_filename)
        job_data_ref[job_id]["assets"]["music_status"] = "processing"
        try:
            # Call with the full output_path
            downloaded_music_path = find_and_download_music(FREESOUND_API_KEY, music_query, music_full_path)
            if downloaded_music_path and os.path.exists(downloaded_music_path):
                job_data_ref[job_id]["assets"]["music_path"] = downloaded_music_path
                job_data_ref[job_id]["assets"]["music_status"] = "completed"
                logger.info(f"[{job_id}] Background music downloaded: {downloaded_music_path}")
                active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Background music downloaded.")
            else:
                 raise ValueError("find_and_download_music returned no valid path.")
        except Exception as e:
            error_msg = f"Background music download failed: {e}"
            logger.error(f"[{job_id}] {error_msg}")
            job_data_ref[job_id]["assets"]["music_status"] = "failed"
            current_error = job_data_ref[job_id].get("error")
            new_error_part = "Music Download Failed"
            job_data_ref[job_id]["error"] = f"{current_error} | {new_error_part}" if current_error else new_error_part
            active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Error: {error_msg}")
    else:
        logger.warning(f"[{job_id}] No music_vibe found. Skipping background music.")
        job_data_ref[job_id]["assets"]["music_status"] = "skipped"
        active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Skipped background music (no query).")

    logger.info(f"[{job_id}] Asset generation initiated. Waiting for Argil webhooks (if any) and for Pexels/audio tasks to complete.")
    active_jobs_ref[job_id].append(f"[{datetime.now().isoformat()}] Asset generation initiated. Waiting for completion...")
    # The rest of the process (assembly) will be triggered by webhook updates or polling leading to check_job_completion.


# Note: check_job_completion and run_assembly_and_captioning can be reused from heygen_workflow
# or main.py if they are generic enough. For now, assume they are available in the execution context (e.g. main.py)
# If they need to be Argil-specific, they would be defined or adapted here.
# The assembly function itself (e.g., assemble_argil_video) will need to be created in editor.py
# and called by run_assembly_and_captioning.

# Example of how to run (will be triggered by FastAPI endpoint later)
# async def main_test_argil():
#     test_job_id = f"argil_test_{uuid.uuid4().hex[:8]}"
#     # Create a dummy script2.md in public folder for testing
#     # Ensure NGROK_PUBLIC_URL, ARGIL_API_KEY etc. are set in .env
#     # workspace_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
#     # test_script_path = os.path.join(workspace_root, "public", "script2.md")
#     # if not os.path.exists(test_script_path):
#     #     print(f"Test script {test_script_path} not found. Please create it.")
#     #     return
#     # await run_argil_workflow(test_job_id, test_script_path)
#     print("Argil Workflow function finished initiation.")
#     # print("Job Data:", job_data.get(test_job_id))

# if __name__ == "__main__":
#     # Make sure to run with asyncio.run(main_test_argil())
#     pass
